services:
  inference_api:
    image: openvino/model_server:latest
    command: |
      --model_name challenge2
      --model_path /models
      --layout NCHW:NCHW
      --rest_port 9001
      --port 9000
    ports:
      - 9000:9000
      - 9001:9001
    volumes:
      - "./challenge2/models:/models:ro"
  
  freshwater_app_web:
    build: challenge1/app_web
    ports:
      - 8001:8001
    environment:
      - PORT=8001
      - SHOW_APP_MENU=true
    healthcheck:
      test: ["CMD", "curl", "-f", "http://freshwater_app_web:8001"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s

  cropweed_app_web:
    build: challenge2/app_web
    ports:
      - 8002:8002
    depends_on:
      - inference_api
    environment:
      - PORT=8002
      - SHOW_APP_MENU=true
      - MODEL_NAME=challenge2
      - REST_API_HOST=http://inference_api:9001
      - GRPC_API_HOST=inference_api:9000
    healthcheck:
      test: ["CMD", "curl", "-f", "http://cropweed_app_web:8002"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s

  main_web_app:
    build: main
    ports:
      - 8000:80
